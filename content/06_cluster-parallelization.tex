\section{Cluster Parallelisierung - mpiexec -n <<size>>}

viele CPU Cores, Faktor 100 und mehr!

\subsection{Message Passing Interface (MPI)}

Verteiltes Programmiermodell, basiert auf Actor/CSP-Prinzip, Jeder Prozess hat seine Identifikation (Rank) und arbeitet unabhängig in seinem Adressraum (\textcolor{darkGreen}{kein Shared Memory/kein Data Race}), starten und terminieren synchron $\rightarrow$ können untereinander kommunizieren (Nachrichten Senden/Empfangen), Synchronisation mit Barrieren \textcolor{red}{Senden blockiert bis Empfangen!}


\begin{lstlisting}
#include <stdio.h> #include "mpi.h"
int main(int argc, char* argv[]){
  // MPI Initialisierung
  MPI_Init(&argc, &argv);

  // Prozess Identifikation
  int rank;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank); // Prozess-Nummer innerhalb Gruppe

  int size;
  MPI_Comm_size(MPI_COMM_WORLD, &size); // Gesamtanzahl der Prozesse

  char name[MPI_MAX_PROCESSOR_NAME]; int len;
  MPI_Get_processor_name(name, &len);
  printf("MPI process %i", rank, name);

  // Senden/Empfangen eines Int-Wertes
  int tag = 0; // frei wählbare Nummer für Nachrichtenart >=0
  int sender = 0;
  int length = 1;
  if (rank == 0) {
    // generate/load data
\end{lstlisting}
\begin{minipage}[t]{0.5\linewidth}
    \begin{lstlisting}
    int value = rand();
    \end{lstlisting}
\end{minipage}
\begin{minipage}[t]{0.5\linewidth}
    \begin{lstlisting}
    array = read_array_file(&length);
    int partition = length / size;
    // for int offset = rank * partition;
    \end{lstlisting}
\end{minipage}
\begin{lstlisting}
    for (int to = 1; to < size; to++) { // verteile auf andere Prozesse
      MPI_Send(&value, length, MPI_INT, to, tag, MPI_COMM_WORLD); }
  } else { // Sub-Prozesses
    int value;
    MPI_Recv(&value, length, MPI_INT, sender, tag, MPI_COM.., MPI_STATUS_IGNORE);
    printf("%i received by %i", value, rank); } // compute subtask

  // Warte, dass alle Prozesse Barriere erreichen
  MPI_Barrier(MPI_COMM_WORLD);

  // Aggregation von Teilresultaten (zwischen Prozessen)
  // Jeder erhält Gesamtresultat als Rückgabewert, beinhaltet implizite Barriere/Broadcast über alle Prozesse
  MPI_AllReduce(&value, &total, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);

  // Nur Prozess receiverRank sieht das Gesamtresultat, kein Broadcast
  MPI_Reduce(&value, &total, 1, MPI_INT, MPI_SUM, receiverRank, MPI_COMM_WORLD)

  MPI_Finalize(); // MPI Finalisierung
  return 0; }
\end{lstlisting}

\textbf{Communicator} Gruppe von MPI-Prozessen \lstinline{MPI_COMM_WORLD} Communicator World, Gruppe aller Prozesse einer MPI-Programmausführung

\textbf{MPI Datentypen} \lstinline{MPI_CHAR} \lstinline{MPI_SHORT} \lstinline{MPI_INT} \lstinline{NPI_LONG} \lstinline{MPI_LONG_LONG} \lstinline{MPI_UNSIGNED} \lstinline{MPI_FLOAT}\lstinline{MPI_DOUBLE}

\textbf{Aggregatoren} \lstinline{MPI_MAX} \lstinline{MPI_MIN} \lstinline{MPI_SUM} \lstinline{MPI_PROD}

\textbf{Kommunikationskonzepte}
\textcolor{blue}{Broadcast} \lstinline{MPI_Bcast(&input, 1, MPI_INT, 0 /* sender */, MPI_COMM_WORLD)}
\textcolor{blue}{All to All} \lstinline{MPI_All(&input_array, size, MPI_INT, &output_array, size, MPI_INT, MPI_COMM_WORLD)}
\textcolor{blue}{Scatter} \lstinline{MPI_Scatter(&input_array, size, MPI_INT, &output_value, 1, MPI_INT, 0 /* sender */, MPI_COMM_WORLD)}
\textcolor{blue}{Gather} \lstinline{MPI_Gather(&input_value, 1, MPI_INT, &output_array, 1, MPI_INT, 0 /* receiver */, MPI_COMM_WORLD)}

%\subsubsection{Monte Carlo - C}
%
%\begin{lstlisting}
%long count_hits(long trials) {
%  long hits = 0, i;
%  for (i = 0; i < trials; i++) {
%    double x = (double)rand()/RAND_MAX;
%    double y = (double)rand()/RAND_MAX;
%    if (x * x + y * y <= 1) { hits++; } }
%  return hits; }
%int main(int argc, char* argv[]) {
%  MPI_Init(&argc, &argv);
%
%  int rank, size;
%  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
%  MPI_Comm_size(MPI_COMM_WORLD, &size);
%
%  srand(rank * 4711); // willkürlicher Seed für jeden Prozess
%  long hits = count_hits(TRIALS / size) // Jeder Prozess rechnet Bruchteil
%  long total;
%  MPI_Reduce(&hits, &total, 1, MPI_LONG, MPI_SUM, 0, MPI_COMM_WORLD); // Prozess 0 erhält Gesamtwert
%  if (rank==0) { double pi = 4 * ((double)total / TRIALS); }
%
%  long hits = count_hits(TRIALS);
%  double pi = 4 * ((double)hits / TRIALS); }
%\end{lstlisting}
